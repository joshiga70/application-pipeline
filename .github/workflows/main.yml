name: CI/CD Pipeline for Cloud-Native Application

on:
  push:
    branches:
      - main

env:
  AWS_REGION: eu-north-1
  ECR_REPOSITORY_NAME: ${{ secrets.ECR_REPOSITORY_NAME }}
  CLUSTER_NAME: demo-eks-cluster
  DOCKER_IMAGE_NAME: webapp
  HELM_CHART_PATH: ./helmdeployment
  AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      # Checkout the code
      - name: Checkout code
        uses: actions/checkout@v3

      # Configure AWS credentials
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      # Login to ECR
      - name: Login to AWS ECR
        run: |
          aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin ${AWS_ACCOUNT_ID}.dkr.ecr.$AWS_REGION.amazonaws.com

      # Build Docker image
      - name: Build Docker image
        run: |
          docker build -t $DOCKER_IMAGE_NAME ./webapp

      # Create ECR repository (if not exists)
      - name: Create ECR repository
        run: |
          aws ecr describe-repositories --repository-names $ECR_REPOSITORY_NAME || \
          aws ecr create-repository --repository-name $ECR_REPOSITORY_NAME

      # Tag and push Docker image to ECR
      - name: Tag and Push Docker image to ECR
        run: |
          IMAGE_URI=${AWS_ACCOUNT_ID}.dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_REPOSITORY_NAME:latest
          docker tag $DOCKER_IMAGE_NAME:latest $IMAGE_URI
          docker push $IMAGE_URI

  create-cluster:
    runs-on: ubuntu-latest
    needs: build
    steps:
      # Checkout the code
      - name: Checkout code
        uses: actions/checkout@v3

      # Configure AWS credentials
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      # check if the cluster already exists
      - name: Check if EKS cluster exists
        id: check-cluster
        run: |
         if aws eks describe-cluster --name ${{env.CLUSTER_NAME}} --region $AWS_REGION; then
           echo "Cluster already exists."
           echo "exists=true" >> $GITHUB_ENV
         else
           echo "Cluster does not exist."
           echo "exists=false" >> $GITHUB_ENV
         fi

       # Create new kubernetes cluster on AWS
      - name: Create new kubernetes cluster on AWS
        if: env.exists == 'false'
        run: |
          aws eks create-cluster  --name ${{env.CLUSTER_NAME}} --role-arn arn:aws:iam::${AWS_ACCOUNT_ID}:role/EKS-role-pipeline   --resources-vpc-config subnetIds=subnet-0007609ae4b181886,subnet-0d5f88e40b51bfef1,securityGroupIds="sg-0404865abc19be094",endpointPublicAccess=true,endpointPrivateAccess=false --tags createdFor=Demo,ownedBy=Girija
      - name: Wait for cluster initialization
        if: env.exists == 'false'
        run: |
         sleep 500
      - name: Create new node group for cluster 
        if: env.exists == 'false'
        run: |
          aws eks create-nodegroup --cluster-name ${{env.CLUSTER_NAME}} --nodegroup-name demo-eks-nodes --subnets subnet-0007609ae4b181886 subnet-0d5f88e40b51bfef1 --node-role arn:aws:iam::${AWS_ACCOUNT_ID}:role/EKS-Node-Role --instance-type t3.medium --disk-size 20 --scaling-config minSize=3,maxSize=5,desiredSize=3 --tags createdFor=Demo,ownedBy=Girija
    
      - name: Cluster already exists message
        if: env.exists == 'true'
        run: echo "Skipping cluster creation as it already exists."

  deploy:
    runs-on: ubuntu-latest
    needs: create-cluster
    steps:
      # Checkout the code
      - name: Checkout code
        uses: actions/checkout@v3

      # Configure AWS credentials
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      # Set up kubeconfig
      #- name: Set up kubeconfig
       # run: |
       #   echo "${{ secrets.KUBE_CONFIG_DATA }}" | base64 -d > ~/.kube/config

      # Add Helm repository and update
      - name: Set up Helm
        run: helm repo add stable https://charts.helm.sh/stable && helm repo update

      # set kube-config as current cluster
      - name: Set current context
        run : aws eks update-kubeconfig --name ${{ env.CLUSTER_NAME }}

      # Deploy application using Helm charts
      - name: Helm deployment
        run: |
          cd helmdeployment
          IMAGE_URI=${AWS_ACCOUNT_ID}.dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_REPOSITORY_NAME:latest
          helm uninstall helmdeployment -n project 
          helm install helmdeployment . --create-namespace --namespace project
      # Verify deployment
      - name: Verify deployment
        run: |
          kubectl get all -n project
          sleep 20
          kubectl get all -n project


      - name: Capture Service Description
        if: always()  # Ensures this step runs even if the previous steps fail
        run: |
          echo "Capturing kubectl describe svc output..."
          kubectl describe svc web-service -n project > webapp-service-description.txt
        shell: bash
        
      - name: Upload Service Description as Artifact
        uses: actions/upload-artifact@v3
        with:
          name: webapp-service-description
          path: webapp-service-description.txt


      # Get the external IP of the service 
      - name: Extract LoadBalancer Ingress Value
        id: extract-lb-ingress
        run: |
          echo "Extracting LoadBalancer Ingress value from service description..."
          LOADBALANCER_INGRESS=$(grep -i "LoadBalancer Ingress" webapp-service-description.txt | awk '{print $3}')
          if [ -n "$LOADBALANCER_INGRESS" ]; then
            echo "LoadBalancer Ingress found: $LOADBALANCER_INGRESS"
            echo "WEBAPP_LINK=http://$LOADBALANCER_INGRESS:8080" >> $GITHUB_ENV
          else
            echo "Error: LoadBalancer Ingress value not found."
          
          fi
        shell: bash
      # printing webapp link variable
      - name: Print WebApp Link
        run: |
          echo "WebApp Link is: $WEBAPP_LINK"
        shell: bash


         

  test:
    name: Cypress Test
    runs-on: ubuntu-latest
    needs: deploy
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Install Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '22'

      - name: Install Dependencies
        run: |
          cd cypress-ui-testsuite
          npm install
          

      - name: Run Cypress Tests
        env:
          WEBAPP_URL: ${{ env.WEBAPP_LINK }}
        run: |
          echo $WEBAPP_URL
          cd cypress-ui-testsuite
          jq '.env.url = "${{ env.WEBAPP_LINK }}"' cypress.json > tmp.json && mv tmp.json cypress.json
          echo "Updated cypress.json:"
          cat cypress.json
          sh executor.sh 
          echo "Running Cypress tests on $WEBAPP_URL"


      - name: Archive Cypress Reports
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: cypress-reports
          path: |
            cypress/videos
            cypress/screenshots
            reports/cucumber-htmlreport.html/index.html
          
          
            
